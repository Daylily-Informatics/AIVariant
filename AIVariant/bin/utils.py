###
# Written by Hyeonseong Jeon
# email: jun0605@snu.ac.kr
###

from typing import *
import random
import os
import logging
import functools

LOGGER_LINE = "\n====================\n"


def get_logger(logger_name):
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s | [%(levelname)s] %(name)s: %(message)s',
                        datefmt='%d-%b-%Y %H:%M:%S')
    return logging.getLogger(logger_name)


def print_args(args):
    print("", flush=True)
    for arg in vars(args):
        print(arg.upper() + ':', getattr(args, arg))
    print("", flush=True)


def with_log(fn):
    def with_log_fn(*args, **kwargs):
        logger = get_logger(f"::{fn.__name__}")

        logger.info("Start")

        print(f"----Logs generated by external software, possibly empty----",
              flush=True)

        ret = fn(*args, **kwargs)

        print(f"-----------------------------------------------------------",
              flush=True)

        logger.info("Completed")

        return ret

    return with_log_fn


class Divider():
    """
    Divide genome to windows for parallel processing
    """

    def __init__(self, chromosomes: List[str], fai_file: str,
                 window_size: int = 500000):
        self.chromosomes = chromosomes
        self.fai_file = fai_file
        self.window_size = window_size

        self.contig_lengths = dict()
        self.windows = dict()

    def get_contig_lengths(self):
        with open(self.fai_file, "r") as f:
            for line in f:
                fields = line.strip().split("\t")

                self.contig_lengths['chr' + fields[0]] = int(fields[1])

    def generate_windows(self):
        for chrom in self.chromosomes:
            self.windows[chrom] = []
            start = 0
            while (start < self.contig_lengths[chrom]):
                self.windows[chrom].append([start,
                                            min(start + self.window_size,
                                                self.contig_lengths[chrom])])
                start += self.window_size

    def __call__(self):
        self.get_contig_lengths()
        self.generate_windows()
        return self.windows


class Utils():
    """
    Common utility function for bam file read processing
    """

    @staticmethod
    def get_bqsumdiff(tumor_depth):
        return 35 * tumor_depth * 2 / 30

    @staticmethod
    def get_bqsumn(normal_depth):
        return 30 * normal_depth * 1 / 30

    @staticmethod
    def get_unrolled_cigar_chars(read):
        cigar_char = "MIDNSHP=XB"
        return [cigar_char[pair[0]] for pair in read.alignment.cigartuples for
                _ in range(pair[1])]

    @staticmethod
    def order(pos, ref, alt, read):  # pos is 0-based

        # SNV
        query_pos = read.query_position
        if query_pos is None:
            return (0, read.alignment.mapping_quality, -1)

        mq = read.alignment.mapping_quality
        bq = read.alignment.query_qualities[query_pos]
        query_base = read.alignment.query_sequence[query_pos].upper()
        if query_base not in "ACGT":
            return (0, mq, bq)

        if query_base == alt:
            return (100, mq, bq)

        cigar_operations = [pair[0] for pair in read.alignment.cigartuples for
                            _ in range(pair[1])]
        aligned_pairs = read.alignment.get_aligned_pairs()

        assert len(cigar_operations) == len(aligned_pairs)

        # inserts or deletes after the query position
        len_inserts = 0
        bqsum_inserts = 0
        ap_idx = len(aligned_pairs)
        for i, p in enumerate(aligned_pairs):
            if p[1] == pos:
                ap_idx = i + 1
        while ap_idx < len(aligned_pairs) and aligned_pairs[ap_idx][
            1] is None and cigar_operations[ap_idx] == 1:
            len_inserts += 1
            read_idx = aligned_pairs[ap_idx][0]
            bqsum_inserts += read.alignment.query_qualities[read_idx]
            ap_idx += 1

        len_deletes = 0
        bqsum_deletes = 0
        ap_idx = len(aligned_pairs)
        for i, p in enumerate(aligned_pairs):
            if p[1] == pos:
                ap_idx = i + 1
        while ap_idx < len(aligned_pairs) and aligned_pairs[ap_idx][
            0] is None and cigar_operations[ap_idx] == 2:
            len_deletes += 1
            bqsum_deletes += 35
            ap_idx += 1

        indel_var, indel_bq = None, None

        if len_inserts == 1:
            indel_var = "I1"
            indel_bq = bqsum_inserts / len_inserts
        elif len_inserts == 2:
            indel_var = "I2"
            indel_bq = bqsum_inserts / len_inserts
        elif len_inserts >= 3:
            indel_var = "I3"
            indel_bq = bqsum_inserts / len_inserts

        if len_deletes == 1:
            indel_var = "D1"
            indel_bq = bqsum_deletes / len_deletes
        elif len_deletes == 2:
            indel_var = "D2"
            indel_bq = bqsum_deletes / len_deletes
        elif len_deletes >= 3:
            indel_var = "D3"
            indel_bq = bqsum_deletes / len_deletes

        if indel_var == alt:
            return (100, mq, indel_bq)

        if indel_var is not None:
            return (50, mq, indel_bq)
        if query_base != ref:
            return (50, mq, bq)

        return (10, mq, bq)

    @staticmethod
    def get_bqsum_and_depth(pos, reads):  # pos is 0-based
        BQSum = {"A": 0, "C": 0, "G": 0, "T": 0, "I1": 0, "I2": 0, "I3": 0,
                 "D1": 0, "D2": 0, "D3": 0}
        depth = 0

        for pileupread in reads:

            # SNV
            query_pos = pileupread.query_position
            if query_pos is None:
                continue

            depth += 1

            query_base = pileupread.alignment.query_sequence[query_pos].upper()
            if query_base not in "ACGT":
                continue

            bq = pileupread.alignment.query_qualities[query_pos]
            BQSum[query_base] += bq

            cigar_operations = [pair[0] for pair in
                                pileupread.alignment.cigartuples for _ in
                                range(pair[1])]
            aligned_pairs = pileupread.alignment.get_aligned_pairs()

            assert len(cigar_operations) == len(aligned_pairs)

            # inserts or deletes after the query position
            len_inserts = 0
            bqsum_inserts = 0
            ap_idx = len(aligned_pairs)
            for i, p in enumerate(aligned_pairs):
                if p[1] == pos:
                    ap_idx = i + 1
            while ap_idx < len(aligned_pairs) and aligned_pairs[ap_idx][
                1] is None and cigar_operations[ap_idx] == 1:
                len_inserts += 1
                read_idx = aligned_pairs[ap_idx][0]
                bqsum_inserts += pileupread.alignment.query_qualities[read_idx]
                ap_idx += 1

            len_deletes = 0
            bqsum_deletes = 0
            ap_idx = len(aligned_pairs)
            for i, p in enumerate(aligned_pairs):
                if p[1] == pos:
                    ap_idx = i + 1
            while ap_idx < len(aligned_pairs) and aligned_pairs[ap_idx][
                0] is None and cigar_operations[ap_idx] == 2:
                len_deletes += 1
                bqsum_deletes += 35
                ap_idx += 1

            if len_inserts == 1:
                BQSum["I1"] += bqsum_inserts / len_inserts
            elif len_inserts == 2:
                BQSum["I2"] += bqsum_inserts / len_inserts
            elif len_inserts >= 3:
                BQSum["I3"] += bqsum_inserts / len_inserts

            if len_deletes == 1:
                BQSum["D1"] += bqsum_deletes / len_deletes
            elif len_deletes == 2:
                BQSum["D2"] += bqsum_deletes / len_deletes
            elif len_deletes >= 3:
                BQSum["D3"] += bqsum_deletes / len_deletes

        return BQSum, depth

    @staticmethod
    def get_cigarstring_from_tuples(cigartuples):
        cigar_operations = {0: "M", 1: "I", 2: "D", 4: "S"}
        cigarstring = ""
        for cigar in cigartuples:
            if cigar[0] not in cigar_operations: return None
            cigarstring += cigar[1] * cigar_operations[cigar[0]]
        return cigarstring

    @staticmethod
    def fetch_reads_from_pileupcolumn(pileupcolumn):
        reads_dict = dict()

        log_path = "/extdata6/baeklab/Hyeonseong/AIVariant/logs"
        log_file = os.path.join(log_path,
                                f'depth_limit_check.{pileupcolumn.reference_id}.{pileupcolumn.reference_name}.{pileupcolumn.reference_pos}.log')
        depth_limit = 8000  # Default hardcoded
        depth_column = 0
        depth_usable = 0

        for pileupread in pileupcolumn.pileups:
            depth_column += 1

            query_pos = pileupread.query_position
            if query_pos is not None:
                base = pileupread.alignment.query_sequence[query_pos]
            else:
                base = 'X'
            usable = query_pos is not None and base in "ACGT"
            if usable: depth_usable += 1

            if pileupread.alignment.is_secondary: continue
            if pileupread.alignment.mapping_quality == 0: continue

            qname = pileupread.alignment.query_name
            if qname not in reads_dict:
                reads_dict[qname] = {"se": [], "fw": [], "rv": []}
            read_category = ReadPreprocess.get_read_category(pileupread)

            reads_dict[qname][read_category].append(pileupread)

        reads = ReadPreprocess.apply_read_category_filter(reads_dict)
        del reads_dict

        reads = [read for read in reads
                 if Utils.get_cigarstring_from_tuples(
                read.alignment.cigartuples) is not None]

        # if depth_column >= depth_limit:
        #     with open(log_file, "w") as log:
        #         print(f"[Warning] {depth_column} exceeds {depth_limit}, usable depth was {depth_usable}", flush=True, file=log)

        return reads


class CandidateWrapper():
    """Parse candidates to input to image generator
    """

    def __init__(self, candidate_files):
        """Construct candidate wrapper

        param candidate_files: full file paths of candidate files to be wrapped
        """

        self.candidate_files = candidate_files
        self.candidates = []

    def generate_candidates(self):
        self.candidates = []
        for candidate_file in self.candidate_files:
            with open(candidate_file, "r") as f:
                header = f.readline()
                tumor_bam_file, normal_bam_file, ref_file = header.strip().split(
                    "\t")
                for line in f:
                    chrom, pos, ref, alt = line.strip().split("\t")
                    pos = int(pos)
                    self.candidates.append((tumor_bam_file, normal_bam_file,
                                            ref_file, chrom, pos, ref, alt))

    def wrap(self):
        self.generate_candidates()
        return self.candidates


class ReadPreprocess():
    """Collection of read preprocess methods for image generation
    """

    @staticmethod
    def get_read_category(read):
        if not read.alignment.is_paired:
            return "se"
        else:
            if read.alignment.is_read1:
                return "fw"
            else:
                return "rv"

    @staticmethod
    def read_category_sanity(read_category_dict):
        pair = max(len(read_category_dict["fw"]),
                   len(read_category_dict["rv"])) > 0
        single = len(read_category_dict["se"]) > 0
        if not pair and not single: return False
        if pair and single: return False
        return True

    @staticmethod
    def reads_in_category_sanity(reads):
        if len(reads) < 2:
            return True
        else:
            cigar = reads[0].alignment.cigarstring
            return all([read.alignment.cigarstring == cigar for read in reads])

    @staticmethod
    def get_better_category(read_category_dict):
        if len(read_category_dict["fw"]) == 0:
            return "rv"
        elif len(read_category_dict["rv"]) == 0:
            return "fw"
        else:
            query_pos_fw = read_category_dict["fw"][0].query_position
            query_pos_rv = read_category_dict["rv"][0].query_position
            if query_pos_fw is not None:
                bq_fw = read_category_dict["fw"][0].alignment.query_qualities[
                    query_pos_fw]
            else:
                bq_fw = 0
            if query_pos_rv is not None:
                bq_rv = read_category_dict["rv"][0].alignment.query_qualities[
                    query_pos_rv]
            else:
                bq_rv = 0
            if bq_fw > bq_rv:
                return "fw"
            elif bq_fw < bq_rv:
                return "rv"
            else:
                return random.choice(["fw", "rv"])
            # else: return "fw" # only for debug

    @staticmethod
    def apply_read_category_filter(reads_dict):
        reads = []
        for qname in reads_dict:
            if not ReadPreprocess.read_category_sanity(
                reads_dict[qname]): continue
            if len(reads_dict[qname]["se"]) > 0: continue
            if not ReadPreprocess.reads_in_category_sanity(
                    reads_dict[qname]["fw"]) \
                    or not ReadPreprocess.reads_in_category_sanity(
                reads_dict[qname]["rv"]):
                continue

            category = ReadPreprocess.get_better_category(reads_dict[qname])
            reads += reads_dict[qname][category]

        return reads

